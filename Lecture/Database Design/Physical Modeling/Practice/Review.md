-----
### 정리
-----
1. 물리적 모델링 
   - 데이터베이스 설계의 마지막 단계로, 논리적 모델을 실제 데이터베이스(MySQL)에 맞는 물리적 스키마로 변환
   - 물리적 모델링의 최종 산출물은 테이블 정의서와 실제 테이블을 생성하는 DDL(CREATE TABLE) 스크립트
   - 핵심 목표는 성능 최적화이며, 이를 위해 인덱스 설계와 역정규화 기법을 적용
   - 물리적 모델링은 테이블 변환, 데이터 타입 정의, 제약 조건 설정, 인덱스 설계, 역정규화 순서로 진행

2. 인덱스 설계 
   - 인덱스는 데이터 조회 속도를 높이는 '목차'와 같으며, 없으면 모든 데이터를 스캔하는 풀 테이블 스캔(Full Table Scan)이 발생
   - MySQL은 PK, UNIQUE, FK 제약 조건에 대해 자동으로 인덱스를 생성
   - WHERE 절에 자주 사용되거나 JOIN의 연결고리가 되는 컬럼에 인덱스를 생성
   - 두 개 이상의 컬럼이 WHERE 절에 함께 자주 사용될 경우 복합 인덱스를 고려하며, 컬럼 순서가 매우 중요 (등호 조건 범위 조건 순)
   - 선택도가 높은 컬럼의 인덱스만으로 충분히 데이터가 걸러진다면, 추가적인 복합 인덱스는 오히려 쓰기(INSERT, UPDATE, DELETE) 성능을 저하시키는 과잉 최적화가 될 수 있으므로 신중해야 함

3. 역정규화 
   - 역정규화는 정규화 원칙을 위배하여 조회 성능을 높이는 기법으로, 최후의 수단으로 고려해야 함
     + 중복 컬럼 추가 : 잦은 JOIN을 피하기 위해 order_item 테이블에 product_name을 추가
       * 이는 주문 당시의 정보를 보존하는 '스냅샷' 데이터로서 비즈니스 요구사항도 만족시킴
     + 파생 컬럼 추가 : 매번 계산해야 하는 값을 미리 계산해 저장
       * orders 테이블에 total_amount(총 주문 금액)를 추가하여 복잡한 집계 연산을 피함
     + 테이블 통합 : orders와 delivery처럼 1:1 관계라도 데이터의 생명주기와 변경 빈도가 다르면 통합하지 않는 것이 좋음
       * 분리된 구조가 유연성과 확장성 측면에서 더 유리

4. 쇼핑몰 테이블 정의서
   - 논리적 모델을 기반으로 컬럼의 영문명, 데이터 타입, 제약 조건 등을 구체적으로 명시한 문서이
   - 모든 테이블에 데이터의 생성 및 수정 이력을 추적하기 위한 감사 컬럼 created_at (생성일)과 updated_at(수정일)을 추가하는 것이 표준
   - 시스템의 시간(created_at)과 비즈니스의 시간(ordered_at)을 명확히 구분해야 함
     + 시스템 시간은 데이터가 DB에 물리적으로 저장된 시각이며, 비즈니스 시간은 실제 주문이 발생한 시각을 의미

5. 쇼핑몰 DDL과 DB 만들기
   - 테이블 정의서를 바탕으로 실제 데이터베이스에 테이블을 생성하는 SQL(CREATE TABLE) 스크립트
   - 인덱스 설계와 역정규화 전략이 모두 반영된 최종 코드로 구성
   - 데이터베이스 초기화(DROP/CREATE), 테이블 생성(DDL), 샘플 데이터 입력(DML)을 포함하는 통합 스크립트
   - 이 스크립트 하나로 언제든지 동일한 구조와 데이터를 가진 개발 및 테스트 환경을 구축할 수 있음

6. 물리적 모델 - ERD 자동 생성
   - MySQL Workbench와 같은 툴을 사용하면 생성된 테이블 구조를 바탕으로 물리적 모델의 ERD를 자동으로 생성하여 시각적으로 확인할 수 있음

7. 쇼핑몰 기능 확인
   - EXPLAIN 명령어를 통해 SQL 쿼리의 실행 계획을 분석하여, 설계한 인덱스가 의도대로 효율적으로 사용되는지 검증
   - 로그인, 회원 주문 목록 조회, 상품 검색, 관리자 주문 조회 등 핵심 기능에서 인덱스가 잘 동작함을 확인
   - 역정규화를 통해 JOIN 이나 복잡한 계산 없이 단순한 쿼리로 빠른 조회가 가능해진 효과를 확인
   - 월별 매출 통계, 베스트셀러 상품, VIP 고객 식별, 재고 부족 상품 확인 등 비즈니스 분석 및 운영에 필요한 복잡한 조회 쿼리 예시를 다루었음
   - 잘 설계된 테이블 구조는 복잡한 통계 및 분석 쿼리도 효율적으로 처리할 수 있는 기반
